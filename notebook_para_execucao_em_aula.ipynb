{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18f27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c66fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log-transform\n",
    "def log_transform(X, columns):\n",
    "    X = X.copy()\n",
    "    for col in columns:\n",
    "        X[col] = np.log(X[col])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef566be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_column_names(df):\n",
    "    df = df.rename(columns={\n",
    "        'Temperature': 'Temperatura',\n",
    "        'Humidity': 'Umidade',\n",
    "        'Wind Speed': 'Velocidade_do_Vento',\n",
    "        'Cloud Cover': 'Cobertura_de_Nuvens',\n",
    "        'Pressure': 'Pressao',\n",
    "        'Location': 'Localizacao',\n",
    "        'Rain Tomorrow': 'Chovera_Amanha',\n",
    "        'Precipitation': 'Precipitacao',\n",
    "        'Date':'Data',\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7868963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(date):\n",
    "        month = date.month\n",
    "        day = date.day\n",
    "        if ((month >= 3 and day >= 20) and (month <= 6 and day < 21)):\n",
    "                return 'Primavera'\n",
    "        elif (month >= 6 and ( month <= 9 and day < 23)):\n",
    "                return 'Verão'\n",
    "        elif (month >= 9 and (month <= 12 and day < 21)):\n",
    "                return 'Outono'\n",
    "        else:\n",
    "                return 'Inverno'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec4db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeamento completo de cidades para estados\n",
    "cidade_para_estado = {\n",
    "    'Los Angeles': 'California', \n",
    "    'Chicago': 'Illinois', \n",
    "    'Houston': 'Texas',\n",
    "    'Phoenix': 'Arizona',\n",
    "    'Philadelphia': 'Pennsylvania',\n",
    "    'San Antonio': 'Texas', \n",
    "    'San Diego': 'California',\n",
    "    'Dallas': 'Texas',\n",
    "    'San Jose': 'California', \n",
    "    'Austin': 'Texas', \n",
    "    'Jacksonville': 'Florida', \n",
    "    'Fort Worth': 'Texas',\n",
    "    'Columbus': 'Ohio', \n",
    "    'Indianapolis': 'Indiana', \n",
    "    'Charlotte': 'North Carolina', \n",
    "    'San Francisco': 'California',\n",
    "    'Seattle': 'Washington', \n",
    "    'Denver': 'Colorado', \n",
    "    'New York': 'New York', \n",
    "    'Washington D.C.': \n",
    "    'District of Columbia'\n",
    "}\n",
    "estado_para_regiao = {\n",
    "    'California': 'Oeste',\n",
    "    'Illinois': 'Meio-Oeste',\n",
    "    'Texas': 'Sul',\n",
    "    'Arizona': 'Oeste',\n",
    "    'Pennsylvania': 'Nordeste',\n",
    "    'Florida': 'Sul',\n",
    "    'Ohio': 'Meio-Oeste',\n",
    "    'Indiana': 'Meio-Oeste',\n",
    "    'North Carolina': 'Sul',\n",
    "    'Washington': 'Oeste',\n",
    "    'Colorado': 'Oeste',\n",
    "    'New York': 'Nordeste',\n",
    "    'District of Columbia': 'Sul'\n",
    "}\n",
    "def cidade_para_regiao(cidade: pd.Series) -> str:\n",
    "    cidade = cidade.title()\n",
    "    estado = cidade_para_estado.get(cidade)\n",
    "    return estado_para_regiao.get(estado) if estado else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b19f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_pt = ['Temperatura', 'Umidade', 'Velocidade_do_Vento', 'Cobertura_de_Nuvens', 'Pressao']\n",
    "categorical_features_pt = ['Estacao', 'Regiao']\n",
    "\n",
    "def pre_processar_df(df:pd.DataFrame, numeric_columns):\n",
    "    # Transformando os dados numéricos para o log\n",
    "    df = log_transform(df, numeric_columns)\n",
    "\n",
    "    df.sort_values(by='Data', inplace=True, ascending=True)\n",
    "\n",
    "    # Cria a coluna Estacao\n",
    "    df['Data'] = pd.to_datetime(df['Data'])\n",
    "    \n",
    "    df[\"Estacao\"] = df[\"Data\"].apply(get_season)\n",
    "    \n",
    "    # Cria a coluna Regiao\n",
    "    df['Regiao'] = df['Localizacao'].apply(cidade_para_regiao)\n",
    "\n",
    "    # Remove colunas originais que não serão mais usadas\n",
    "    df = df.drop(['Data', 'Localizacao'], axis=1)\n",
    "    return df\n",
    "\n",
    "# Para usar no pipeline:\n",
    "preprocess_func = FunctionTransformer(pre_processar_df, kw_args={'numeric_columns': numeric_features_pt}, validate=False)\n",
    "\n",
    "\n",
    "preprocess_before_transforms_pipeline = Pipeline([\n",
    "    ('preprocess_func', preprocess_func)\n",
    "])\n",
    "\n",
    "# Transformadores\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Preprocessamento\n",
    "# Cria o pré-processador\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features_pt),\n",
    "    ('cat', categorical_transformer, categorical_features_pt)\n",
    "], remainder='passthrough')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess_func', preprocess_func),\n",
    "    ('preprocessor', preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7eefd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('usa_rain_prediction_dataset_2024_2025.csv')\n",
    "df = update_column_names(df)\n",
    "\n",
    "X = df.drop(columns=['Chovera_Amanha'])\n",
    "y = df['Chovera_Amanha'].values\n",
    "\n",
    "_,X_test,_,y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_test = pipeline.transform(X_test)\n",
    "\n",
    "# Carregando o modelo\n",
    "modelo = joblib.load('modelo_rain_prediction.pkl')\n",
    "# Fazendo previsões\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'Acurácia: {accuracy:.4f}')\n",
    "print(f'Precisão: {precision:.4f}')\n",
    "print(f'Sensibilidade: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "# plotando as métricas\n",
    "def plot_metrics(y_test, y_pred):\n",
    "    metrics = {\n",
    "        'Acurácia': accuracy_score(y_test, y_pred),\n",
    "        'Precisão': precision_score(y_test, y_pred),\n",
    "        'Sensibilidade': recall_score(y_test, y_pred),\n",
    "        'F1 Score': f1_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=list(metrics.keys()), y=list(metrics.values()))\n",
    "    plt.title('Métricas de Avaliação do Modelo')\n",
    "    plt.ylabel('Valor')\n",
    "    plt.xlabel('Métricas')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
